{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# move to your directory\n",
    "import os\n",
    "os.chdir('/content/drive/MyDrive/CrackSegmentation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clone repository\n",
    "!git clone https://github.com/toshimickey/crack-segmentation-tutorial.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# move directory after clone\n",
    "os.chdir('crack-segmentation-tutorial')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install segmentation_models_pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.dataset import make_datapath_list, CrackDataset, CrackTransform\n",
    "from utils.loss_function import DiceBCELoss\n",
    "from utils.module import EarlyStopping\n",
    "from utils.segmentation_eval import DiceScore, Accuracy, Precision, Recall, Specificity\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "import torch.utils.data as data\n",
    "import segmentation_models_pytorch as smp\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath = make_datapath_list(nfold=5)\n",
    "train_paths, val_paths = datapath.get_train_val_lists(fold_index=0)\n",
    "test_paths = datapath.get_test_lists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_paths)\n",
    "print(val_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CrackDataset(train_paths[0], train_paths[1],transform=CrackTransform(crop_size=256))\n",
    "val_dataset = CrackDataset(val_paths[0], val_paths[1],transform=CrackTransform(crop_size=256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualization\n",
    "i = 0\n",
    "img, anno = train_dataset.__getitem__(i)\n",
    "img = img.clone().numpy()\n",
    "img = img.transpose((1,2,0))\n",
    "\n",
    "anno = anno.clone().numpy()\n",
    "anno = np.asarray(anno, np.float64)\n",
    "anno = anno.transpose((1,2,0))\n",
    "\n",
    "plt.figure(figsize=(15,15))\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(img)\n",
    "plt.title('Image')\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(anno, cmap='gray')\n",
    "plt.title('Mask')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use segmentation_models_pytorch\n",
    "model = smp.DeepLabV3Plus(\n",
    "    encoder_name='resnet18',\n",
    "    encoder_weights='imagenet',\n",
    "    in_channels=3,\n",
    "    classes=1\n",
    ")\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training (Cross Validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set config\n",
    "nfold = 5\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "loss_criterion = DiceBCELoss()\n",
    "accuracy_criterion = DiceScore()\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "patience = 10\n",
    "num_epochs = 100\n",
    "crop_size = 256\n",
    "batch_size = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataloaders, loss_criterion, accuracy_criterion, optimizer, num_epochs, device, patience, fold_index, timestamp):\n",
    "    model.to(device)\n",
    "    earlystopping = EarlyStopping(patience=patience)\n",
    "    os.makedirs(f'weights/{timestamp}/fold{fold_index+1}', exist_ok=True)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}')\n",
    "        print('-' * 10)\n",
    "\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_accuracy = 0.0\n",
    "\n",
    "            for images, labels in dataloaders[phase]:\n",
    "                images = images.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(images)\n",
    "                    loss = loss_criterion(outputs, labels)\n",
    "                    accuracy = accuracy_criterion(outputs, labels)\n",
    "\n",
    "                    # Backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                running_loss += loss.item() * images.size(0)\n",
    "                running_accuracy += accuracy.item() * images.size(0)\n",
    "\n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "            epoch_accuracy = running_accuracy / len(dataloaders[phase].dataset)\n",
    "            print(f'{phase} Loss: {epoch_loss:.4f}  {phase} Accuracy: {epoch_accuracy:.4f}')\n",
    "                   \n",
    "        earlystopping(epoch_loss)\n",
    "        if earlystopping.early_stop:\n",
    "            print(\"Early Stop\")\n",
    "            break\n",
    "        if earlystopping.counter == 0:\n",
    "            print(f\"Validation Loss declined to {earlystopping.best_score}\")\n",
    "            torch.save(model.to('cpu').state_dict(), f'weights/{timestamp}/fold{fold_index+1}/best.pth')\n",
    "            model = model.to(device)\n",
    "            fold_accuracy = epoch_accuracy\n",
    "            \n",
    "        torch.save(model.to('cpu').state_dict(), f'weights/{timestamp}/fold{fold_index+1}/last.pth')\n",
    "        model = model.to(device)\n",
    "\n",
    "    print('Fold training complete')\n",
    "    return fold_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validation\n",
    "datapath = make_datapath_list(nfold)\n",
    "timestamp = datetime.datetime.now().strftime(\"%m%d%H%M\")\n",
    "os.makedirs(f'weights/{timestamp}', exist_ok=True)\n",
    "val_accuracy = []\n",
    "\n",
    "for fold_index in range(nfold):\n",
    "    print(f'Starting fold {fold_index + 1}/{nfold}')\n",
    "    train_paths, val_paths = datapath.get_train_val_lists(fold_index=fold_index)\n",
    "\n",
    "    train_dataset = CrackDataset(train_paths[0], train_paths[1], transform=CrackTransform(crop_size=crop_size))\n",
    "    val_dataset = CrackDataset(val_paths[0], val_paths[1], transform=CrackTransform(crop_size=crop_size))\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    dataloaders = {\n",
    "        'train': train_loader,\n",
    "        'val': val_loader\n",
    "    }\n",
    "\n",
    "    # Train the model\n",
    "    fold_accuracy = train_model(model, dataloaders, loss_criterion, accuracy_criterion, optimizer, num_epochs, device, patience, fold_index, timestamp)\n",
    "    val_accuracy.append(fold_accuracy)\n",
    "\n",
    "print(f\"Validation Accuracy : {sum(val_accuracy)/len(val_accuracy):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate accuracy using each fold model\n",
    "datapath = make_datapath_list(nfold=nfold)\n",
    "test_paths = datapath.get_test_lists()\n",
    "test_dataset = CrackDataset(test_paths[0], test_paths[1],transform=CrackTransform(crop_size=crop_size))\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "c1 = DiceScore()\n",
    "c2 = Accuracy()\n",
    "c3 = Precision()\n",
    "c4 = Recall()\n",
    "c5 = Specificity()\n",
    "\n",
    "for fold_index in range(nfold):\n",
    "    model.load_state_dict(torch.load(f'weights/{timestamp}/fold{fold_index+1}/best.pth'))\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    dice_score = 0\n",
    "    accuracy = 0\n",
    "    precision = 0\n",
    "    recall = 0\n",
    "    specificity = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            dice_score += c1(outputs, labels).item() * images.size(0)\n",
    "            accuracy += c2(outputs, labels).item() * images.size(0)\n",
    "            precision += c3(outputs, labels).item() * images.size(0)\n",
    "            recall += c4(outputs, labels).item() * images.size(0)\n",
    "            specificity += c5(outputs, labels).item() * images.size(0)\n",
    "            \n",
    "    dice_score /= len(test_dataset)\n",
    "    accuracy /= len(test_dataset)\n",
    "    precision /= len(test_dataset)\n",
    "    recall /= len(test_dataset)\n",
    "    specificity /= len(test_dataset)\n",
    "    \n",
    "\n",
    "    print(f'Fold {fold_index+1}: \\\n",
    "        Dice Score: {dice_score:.4f} \\\n",
    "        Accuracy: {accuracy:.4f} \\\n",
    "        Precision: {precision:.4f} \\\n",
    "        Recall: {recall:.4f} \\\n",
    "        Specificity: {specificity:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show prediction\n",
    "model.load_state_dict(torch.load(f'weights/{timestamp}/fold1/best.pth'))\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    images, labels = next(iter(test_loader))\n",
    "    images = images.to(device)\n",
    "    labels = labels.to(device)\n",
    "\n",
    "    outputs = torch.sigmoid(model(images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = images.to('cpu')[i].clone().numpy().transpose((1,2,0))\n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = outputs.to('cpu')[i][0].clone().numpy()\n",
    "plt.imshow(output, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = labels.to('cpu')[i][0].clone().numpy()\n",
    "plt.imshow(label, cmap='gray')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
